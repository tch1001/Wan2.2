torch==2.8
torchvision>=0.19.0
torchaudio
opencv-python>=4.9.0.80
diffusers>=0.31.0
# transformers>=4.49.0,<=4.51.3
transformers>=4.52.0,<5.0.0
tokenizers>=0.20.3
accelerate>=1.1.1
tqdm
imageio[ffmpeg]
easydict
ftfy
dashscope
imageio-ffmpeg
# flash_attn  # Commented out: flash_attn may require special installation steps or specific CUDA/pip wheels; please install manually if needed.
# do NOT pip install flash_attn --no-build-isolation
# https://til.simonwillison.net/python/installing-flash-attention
# install the wheel from github as taught above
numpy>=1.23.5,<2
decord
librosa
peft